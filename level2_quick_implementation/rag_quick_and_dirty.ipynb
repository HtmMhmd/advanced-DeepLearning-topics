{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1833f5c",
   "metadata": {},
   "source": [
    "# Level 2: Quick and Dirty RAG Implementation (Python)\n",
    "\n",
    "This notebook demonstrates a simple, quick-and-dirty implementation of a Retrieval-Augmented Generation (RAG) system for PDF documents. The focus is on clarity and simplicity, not on best practices or optimization.\n",
    "\n",
    "---\n",
    "\n",
    "## Core Steps\n",
    "1. Extract text from a PDF (simulated here for simplicity)\n",
    "2. Split text into chunks\n",
    "3. Generate fake embeddings (random vectors)\n",
    "4. Store chunks in a simple list (instead of a real vector DB)\n",
    "5. Find the most relevant chunks for a question (using cosine similarity)\n",
    "6. Generate an answer by concatenating the most relevant chunks\n",
    "\n",
    "---\n",
    "\n",
    "## Implementation\n",
    "\n",
    "Below is a simple Python implementation. You can run and modify the code to see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db717d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 1. Simulate PDF text extraction (normally you'd use PyMuPDF or similar)\n",
    "pdf_text = \"\"\"\n",
    "Page 1: The sun is the center of our solar system. It provides light and heat to the planets.\n",
    "Page 2: The Earth orbits the sun once every 365 days. The moon orbits the Earth.\n",
    "Page 3: Solar energy can be converted into electricity using solar panels.\n",
    "\"\"\"\n",
    "\n",
    "# 2. Split text into chunks (one per page for simplicity)\n",
    "chunks = [\n",
    "    {\"content\": line, \"metadata\": {\"page\": i+1}}\n",
    "    for i, line in enumerate(pdf_text.strip().split('\\n'))\n",
    "]\n",
    "\n",
    "# 3. Generate fake embeddings (random vectors for demo)\n",
    "def fake_embedding(text):\n",
    "    np.random.seed(abs(hash(text)) % (2**32))\n",
    "    return np.random.rand(5)  # 5-dimensional vector\n",
    "\n",
    "for chunk in chunks:\n",
    "    chunk[\"embedding\"] = fake_embedding(chunk[\"content\"])\n",
    "\n",
    "# 4. Store in a simple list (no real DB)\n",
    "vector_store = chunks\n",
    "\n",
    "# 5. Find most relevant chunks for a question\n",
    "def retrieve_relevant_chunks(question, vector_store, top_k=2):\n",
    "    q_emb = fake_embedding(question)\n",
    "    chunk_embs = np.array([c[\"embedding\"] for c in vector_store])\n",
    "    sims = cosine_similarity([q_emb], chunk_embs)[0]\n",
    "    top_indices = sims.argsort()[-top_k:][::-1]\n",
    "    return [vector_store[i] for i in top_indices]\n",
    "\n",
    "# 6. Generate answer by concatenating relevant chunks\n",
    "def answer_question(question, vector_store):\n",
    "    relevant = retrieve_relevant_chunks(question, vector_store)\n",
    "    answer = \"\\n\".join([f\"[Page {c['metadata']['page']}]: {c['content']}\" for c in relevant])\n",
    "    return answer\n",
    "\n",
    "# ---\n",
    "# Test Example\n",
    "question = \"How does the Earth move around the sun?\"\n",
    "print(\"Question:\", question)\n",
    "print(\"\\nAnswer:\")\n",
    "print(answer_question(question, vector_store))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

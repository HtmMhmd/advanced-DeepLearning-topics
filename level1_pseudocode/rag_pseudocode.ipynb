{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6607cf1b",
   "metadata": {},
   "source": [
    "# Level 1: RAG System Pseudocode\n",
    "\n",
    "This notebook presents the core functionality of a Retrieval-Augmented Generation (RAG) system for PDF documents in simple pseudocode. The purpose is to help beginners understand the logical flow without worrying about syntax details.\n",
    "\n",
    "---\n",
    "\n",
    "## What is RAG (Retrieval-Augmented Generation)?\n",
    "\n",
    "RAG is an AI approach that combines the power of large language models with the ability to retrieve and use specific information from a knowledge base. In this case, our knowledge base consists of PDF documents.\n",
    "\n",
    "## Core Components and Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0177afe8",
   "metadata": {},
   "source": [
    "## 1. PDF Processing\n",
    "\n",
    "The first step is extracting and processing text from PDF documents.\n",
    "\n",
    "```\n",
    "FUNCTION ProcessPDF(pdf_path)\n",
    "    // Extract text from PDF while keeping track of page numbers\n",
    "    text_with_pages = []\n",
    "    \n",
    "    FOR EACH page IN pdf_document\n",
    "        page_text = Extract text from page\n",
    "        page_number = current page number\n",
    "        \n",
    "        IF page_text is not empty\n",
    "            Add (page_text, page_number) to text_with_pages\n",
    "        END IF\n",
    "    END FOR\n",
    "    \n",
    "    // Split text into manageable chunks\n",
    "    chunks = []\n",
    "    \n",
    "    FOR EACH (text, page_number) IN text_with_pages\n",
    "        text_chunks = Split text into smaller pieces\n",
    "        \n",
    "        FOR EACH chunk IN text_chunks\n",
    "            Create dictionary with:\n",
    "                \"content\" = chunk\n",
    "                \"metadata\" = {\"page\": page_number}\n",
    "            \n",
    "            Add dictionary to chunks\n",
    "        END FOR\n",
    "    END FOR\n",
    "    \n",
    "    RETURN chunks\n",
    "END FUNCTION\n",
    "```\n",
    "\n",
    "This process transforms pages of text into smaller, manageable chunks while preserving metadata about which page each chunk came from."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdf18b7",
   "metadata": {},
   "source": [
    "## 2. Embedding Generation\n",
    "\n",
    "Next, we need to create vector representations (embeddings) for each chunk of text.\n",
    "\n",
    "```\n",
    "FUNCTION GenerateEmbeddings(chunks)\n",
    "    // Extract just the text content from each chunk\n",
    "    texts = []\n",
    "    FOR EACH chunk IN chunks\n",
    "        Add chunk[\"content\"] to texts\n",
    "    END FOR\n",
    "    \n",
    "    // Generate embeddings (vector representations)\n",
    "    embeddings = []\n",
    "    \n",
    "    IF using_local_model\n",
    "        embeddings = Generate embeddings using local model\n",
    "    ELSE\n",
    "        TRY\n",
    "            embeddings = Generate embeddings using OpenAI API\n",
    "        CATCH API error\n",
    "            embeddings = Fall back to local embedding model\n",
    "        END TRY\n",
    "    END IF\n",
    "    \n",
    "    // Add embeddings to the original chunks\n",
    "    FOR i = 0 TO length(chunks) - 1\n",
    "        chunks[i][\"embedding\"] = embeddings[i]\n",
    "    END FOR\n",
    "    \n",
    "    RETURN chunks\n",
    "END FUNCTION\n",
    "```\n",
    "\n",
    "Embeddings convert text into numerical vectors that capture semantic meaning, allowing us to find similar texts through vector operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d13ec7a",
   "metadata": {},
   "source": [
    "## 3. Vector Storage\n",
    "\n",
    "Once we have chunks with embeddings, we store them in a vector database for efficient retrieval.\n",
    "\n",
    "```\n",
    "FUNCTION StoreChunks(embedded_chunks, pdf_path, project_id)\n",
    "    // Create a unique collection name based on the project ID\n",
    "    collection_name = \"project_\" + project_id\n",
    "    \n",
    "    // Get or create the collection in the vector database\n",
    "    IF collection exists in database\n",
    "        collection = Get existing collection\n",
    "    ELSE\n",
    "        collection = Create new collection\n",
    "    END IF\n",
    "    \n",
    "    // Prepare data for insertion\n",
    "    ids = []\n",
    "    documents = []\n",
    "    metadatas = []\n",
    "    embeddings = []\n",
    "    \n",
    "    FOR i = 0 TO length(embedded_chunks) - 1\n",
    "        chunk = embedded_chunks[i]\n",
    "        \n",
    "        Generate unique ID based on project_id, pdf_path and i\n",
    "        Add ID to ids\n",
    "        \n",
    "        Add chunk[\"content\"] to documents\n",
    "        \n",
    "        metadata = chunk[\"metadata\"]\n",
    "        metadata[\"pdf_id\"] = pdf_path  // Store source PDF info\n",
    "        Add metadata to metadatas\n",
    "        \n",
    "        Add chunk[\"embedding\"] to embeddings\n",
    "    END FOR\n",
    "    \n",
    "    // Add all data to the collection\n",
    "    collection.add(ids, documents, metadatas, embeddings)\n",
    "END FUNCTION\n",
    "```\n",
    "\n",
    "This allows us to organize and search through document chunks efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad1c0e8",
   "metadata": {},
   "source": [
    "## 4. Query and Retrieval\n",
    "\n",
    "When a question is asked, we find the most relevant chunks of text that might contain the answer.\n",
    "\n",
    "```\n",
    "FUNCTION RetrieveRelevantChunks(question, project_id)\n",
    "    // Generate embedding for the question\n",
    "    question_embedding = Generate embedding for question\n",
    "    \n",
    "    // Get the collection for this project\n",
    "    collection_name = \"project_\" + project_id\n",
    "    collection = Get collection from database\n",
    "    \n",
    "    // Search for similar chunks\n",
    "    results = collection.query(\n",
    "        query_embeddings = [question_embedding],\n",
    "        n_results = number of results to return\n",
    "    )\n",
    "    \n",
    "    // Format results into a usable structure\n",
    "    chunks = []\n",
    "    FOR i = 0 TO length(results[\"ids\"][0]) - 1\n",
    "        chunk = {\n",
    "            \"content\": results[\"documents\"][0][i],\n",
    "            \"metadata\": results[\"metadatas\"][0][i]\n",
    "        }\n",
    "        Add chunk to chunks\n",
    "    END FOR\n",
    "    \n",
    "    RETURN chunks\n",
    "END FUNCTION\n",
    "```\n",
    "\n",
    "This semantic search finds text chunks that are conceptually related to the question, not just keyword matches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20bec1e",
   "metadata": {},
   "source": [
    "## 5. Answer Generation\n",
    "\n",
    "Finally, we use the retrieved chunks and the original question to generate a helpful answer.\n",
    "\n",
    "```\n",
    "FUNCTION GenerateAnswer(question, context_chunks)\n",
    "    // Build context string with citation information\n",
    "    context_texts = []\n",
    "    \n",
    "    FOR EACH chunk IN context_chunks\n",
    "        content = chunk[\"content\"]\n",
    "        pdf_id = chunk[\"metadata\"][\"pdf_id\"]\n",
    "        page = chunk[\"metadata\"][\"page\"]\n",
    "        \n",
    "        formatted_chunk = \"[Document: \" + pdf_id + \", Page \" + page + \"]: \" + content\n",
    "        Add formatted_chunk to context_texts\n",
    "    END FOR\n",
    "    \n",
    "    context = Join context_texts with newlines\n",
    "    \n",
    "    // Build prompt for the language model\n",
    "    prompt = \"Answer the following question based ONLY on the provided context:\n",
    "    \n",
    "    CONTEXT:\n",
    "    \" + context + \"\n",
    "    \n",
    "    QUESTION: \" + question + \"\n",
    "    \n",
    "    INSTRUCTIONS:\n",
    "    1. Answer the question using ONLY information from the provided context.\n",
    "    2. If the context doesn't contain the information needed, respond with 'I cannot answer this question based on the provided documents.'\n",
    "    3. Cite the specific documents and page numbers (e.g., [Document: doc.pdf, Page X]).\n",
    "    4. Be concise and accurate.\n",
    "    \n",
    "    ANSWER:\"\n",
    "    \n",
    "    // Call language model API to generate answer\n",
    "    answer = Send prompt to language model and get response\n",
    "    \n",
    "    // Extract citations from the answer\n",
    "    citations = Extract all citation references from answer using pattern matching\n",
    "    \n",
    "    RETURN (answer, citations)\n",
    "END FUNCTION\n",
    "```\n",
    "\n",
    "This ensures answers are grounded in the actual document content with proper citations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb2a3d0",
   "metadata": {},
   "source": [
    "## 6. Complete RAG Pipeline\n",
    "\n",
    "This brings all the pieces together into a complete system.\n",
    "\n",
    "```\n",
    "FUNCTION RAGPipeline(pdf_path, question, project_id)\n",
    "    // First, process and index the PDF if not already done\n",
    "    IF pdf is not already indexed in project\n",
    "        chunks = ProcessPDF(pdf_path)\n",
    "        embedded_chunks = GenerateEmbeddings(chunks)\n",
    "        StoreChunks(embedded_chunks, pdf_path, project_id)\n",
    "    END IF\n",
    "    \n",
    "    // Now answer the question\n",
    "    relevant_chunks = RetrieveRelevantChunks(question, project_id)\n",
    "    answer, citations = GenerateAnswer(question, relevant_chunks)\n",
    "    \n",
    "    // Return the answer with its citations\n",
    "    RETURN answer, citations\n",
    "END FUNCTION\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512caf12",
   "metadata": {},
   "source": [
    "## Example Scenario\n",
    "\n",
    "Let's walk through a simple example:\n",
    "\n",
    "1. **Input**: \n",
    "   - PDF: \"Solar_System.pdf\"\n",
    "   - Question: \"How long does it take Earth to orbit the sun?\"\n",
    "   - Project ID: \"astronomy\"\n",
    "\n",
    "2. **Processing**:\n",
    "   - PDF is processed into chunks\n",
    "   - Chunk #37 contains: \"The Earth orbits the sun once every 365 days, which we call a year.\"\n",
    "   - Each chunk gets an embedding vector\n",
    "   - All chunks are stored in the \"astronomy\" project collection\n",
    "\n",
    "3. **Query**:\n",
    "   - Question embedding is compared to all chunk embeddings\n",
    "   - Chunk #37 is found to be highly relevant to the question\n",
    "   - The chunk is retrieved with its metadata (page 4)\n",
    "\n",
    "4. **Answer Generation**:\n",
    "   - LLM is given the question and relevant chunk\n",
    "   - Answer: \"Earth takes 365 days to complete one orbit around the sun. [Document: Solar_System.pdf, Page 4]\"\n",
    "\n",
    "This demonstrates how the system can find and use specific information from documents to answer questions with proper citation."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "321b0a07",
   "metadata": {},
   "source": [
    "# Modal: GPU-Accelerated AI Model Training\n",
    "\n",
    "This course covers how to use Modal, a cloud platform for running machine learning workloads, with a focus on GPU-accelerated model training.\n",
    "\n",
    "## What is Modal?\n",
    "\n",
    "Modal is a cloud platform designed for running machine learning and data processing workloads. It allows you to:\n",
    "\n",
    "- Run Python functions in the cloud with zero infrastructure management\n",
    "- Access GPUs on-demand for deep learning\n",
    "- Scale your applications automatically\n",
    "- Deploy endpoints as API services\n",
    "- Run scheduled jobs and batch processing\n",
    "\n",
    "## Why Use Modal for AI Training?\n",
    "\n",
    "- **Access to GPU Hardware**: Use powerful GPUs without purchasing expensive hardware\n",
    "- **Pay-per-use Pricing**: Only pay for the compute you actually use\n",
    "- **Zero Infrastructure Management**: No need to configure servers or manage containers\n",
    "- **Easy Scaling**: Train on multiple GPUs with minimal code changes\n",
    "- **Simplified Deployment**: Easily serve trained models as API endpoints\n",
    "\n",
    "## Course Outline\n",
    "\n",
    "1. Setting Up Modal\n",
    "2. Understanding Modal Concepts\n",
    "3. Running Simple Functions on Modal\n",
    "4. Adding GPU Acceleration\n",
    "5. Training a Deep Learning Model\n",
    "6. Distributed Training\n",
    "7. Deploying Trained Models\n",
    "8. Best Practices and Optimization\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python programming knowledge\n",
    "- Basic understanding of machine learning concepts\n",
    "- A Modal account (we'll cover how to set one up)\n",
    "\n",
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5ca4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Modal and other required packages\n",
    "!pip install modal torch torchvision transformers datasets matplotlib pandas numpy tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b34a0be",
   "metadata": {},
   "source": [
    "## 1. Setting Up Modal\n",
    "\n",
    "To use Modal, you need to:\n",
    "1. Create a Modal account at https://modal.com/\n",
    "2. Install the Modal CLI and Python client\n",
    "3. Set up your authentication token\n",
    "\n",
    "Let's go through these steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "106d4720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication error: 'Image' object has no attribute 'run'\n",
      "Please run '!modal token new' to set up your authentication token.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# First, install the Modal client if you haven't already\n",
    "!pip install -q modal\n",
    "\n",
    "# Import Modal\n",
    "import modal\n",
    "\n",
    "# Set up authentication (you need to run this once)\n",
    "# This will open a browser window to authenticate\n",
    "# !modal token new\n",
    "\n",
    "# Verify that you're authenticated\n",
    "try:\n",
    "    modal.Image.debian_slim().run([\"echo\", \"Hello from Modal!\"])\n",
    "    print(\"Authentication successful! Your Modal setup is working correctly.\")\n",
    "except Exception as e:\n",
    "    print(f\"Authentication error: {e}\")\n",
    "    print(\"Please run '!modal token new' to set up your authentication token.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868b5a45",
   "metadata": {},
   "source": [
    "## 2. Understanding Modal Concepts\n",
    "\n",
    "Before we dive into GPU-accelerated training, let's understand the key concepts in Modal:\n",
    "\n",
    "- **Functions**: Python functions that run in the cloud\n",
    "- **Images**: Docker containers with required dependencies\n",
    "- **Volumes**: Persistent storage for your functions\n",
    "- **Apps**: Groups of functions that can be deployed together\n",
    "- **Secrets**: Secure way to store API keys and other credentials\n",
    "\n",
    "Let's create a simple function to demonstrate how Modal works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7635ae52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Modal User from Modal!\n"
     ]
    }
   ],
   "source": [
    "# Define a basic Modal function\n",
    "\n",
    "import modal\n",
    "\n",
    "app = modal.App(\"basic-demo\")\n",
    "\n",
    "@app.function()\n",
    "def hello_world(name):\n",
    "    return f\"Hello, {name} from Modal!\"\n",
    "\n",
    "# Run the function if this file is executed\n",
    "if __name__ == \"__main__\":\n",
    "    with app.run():\n",
    "        result = hello_world.remote(\"Modal User\")\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c097489a",
   "metadata": {},
   "source": [
    "## 3. Creating a Custom Environment\n",
    "\n",
    "For machine learning, we need to create a custom environment with the required dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85c2995f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed packages:\n",
      "- torch: 2.7.1+cu126\n",
      "- cuda_available: False\n",
      "- transformers: 4.53.1\n",
      "- sklearn: 1.7.0\n"
     ]
    }
   ],
   "source": [
    "from modal import App, Image\n",
    "\n",
    "# Create a custom image with ML dependencies\n",
    "ml_image = Image.debian_slim().pip_install(\n",
    "    \"torch\", \n",
    "    \"torchvision\", \n",
    "    \"transformers\",\n",
    "    \"scikit-learn\",\n",
    "    \"pandas\",\n",
    "    \"matplotlib\",\n",
    "    \"numpy\"\n",
    ")\n",
    "\n",
    "app = App(\"ml-environment\", image=ml_image)\n",
    "\n",
    "@app.function()\n",
    "def check_versions():\n",
    "    import torch\n",
    "    import transformers\n",
    "    import sklearn\n",
    "    \n",
    "    result = {\n",
    "        \"torch\": torch.__version__,\n",
    "        \"cuda_available\": torch.cuda.is_available(),\n",
    "        \"transformers\": transformers.__version__,\n",
    "        \"sklearn\": sklearn.__version__\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with app.run():\n",
    "        versions = check_versions.remote()\n",
    "        print(\"Installed packages:\")\n",
    "        for package, version in versions.items():\n",
    "            print(f\"- {package}: {version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa52e7c",
   "metadata": {},
   "source": [
    "## 4. Adding GPU Acceleration\n",
    "\n",
    "One of the most powerful features of Modal is the ability to easily access GPU hardware. Let's see how to configure a function to use a GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18b4f79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_17056\\417075541.py:13: DeprecationError: 2025-02-07: `gpu=T4(...)` is deprecated. Use `gpu=\"T4\"` instead.\n",
      "  @app.function(gpu=gpu.T4())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test results:\n",
      "- gpu_device: Tesla T4\n",
      "- gpu_time: 0.049875\n",
      "- cpu_time: 0.018355\n",
      "- speedup_factor: 0.368020\n"
     ]
    }
   ],
   "source": [
    "from modal import App, Image, gpu\n",
    "\n",
    "# Create an image with PyTorch and CUDA support\n",
    "gpu_image = Image.debian_slim().pip_install(\n",
    "    \"torch\", \n",
    "    \"torchvision\"\n",
    ")\n",
    "\n",
    "app = App(\"gpu-demo\", image=gpu_image)\n",
    "\n",
    "# Specify the GPU type using the gpu parameter\n",
    "# Available options: T4, A10G, A100, H100\n",
    "@app.function(gpu=gpu.T4())\n",
    "def check_gpu():\n",
    "    import torch\n",
    "    \n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA Device:\", torch.cuda.get_device_name(0))\n",
    "        \n",
    "        # Run a simple test on GPU\n",
    "        x = torch.randn(1000, 1000).cuda()\n",
    "        y = torch.randn(1000, 1000).cuda()\n",
    "        \n",
    "        # Measure time for matrix multiplication on GPU\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        z = torch.matmul(x, y)\n",
    "        torch.cuda.synchronize()\n",
    "        gpu_time = time.time() - start_time\n",
    "        \n",
    "        # For comparison, do the same on CPU\n",
    "        x_cpu = x.cpu()\n",
    "        y_cpu = y.cpu()\n",
    "        start_time = time.time()\n",
    "        z_cpu = torch.matmul(x_cpu, y_cpu)\n",
    "        cpu_time = time.time() - start_time\n",
    "        \n",
    "        return {\n",
    "            \"gpu_device\": torch.cuda.get_device_name(0),\n",
    "            \"gpu_time\": gpu_time,\n",
    "            \"cpu_time\": cpu_time,\n",
    "            \"speedup_factor\": cpu_time / gpu_time\n",
    "        }\n",
    "    \n",
    "    return {\"error\": \"CUDA not available\"}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with app.run():\n",
    "        result = check_gpu.remote()\n",
    "        print(\"\\nTest results:\")\n",
    "        for key, value in result.items():\n",
    "            if isinstance(value, float):\n",
    "                print(f\"- {key}: {value:.6f}\")\n",
    "            else:\n",
    "                print(f\"- {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1790356",
   "metadata": {},
   "source": [
    "## 5. Training a Deep Learning Model\n",
    "\n",
    "Now, let's train a simple deep learning model using a GPU on Modal. We'll train a convolutional neural network (CNN) on the MNIST dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dbb854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modal import App, Image, gpu, mount\n",
    "import os\n",
    "\n",
    "# Create an image with deep learning dependencies\n",
    "dl_image = Image.debian_slim().pip_install(\n",
    "    \"torch\", \n",
    "    \"torchvision\", \n",
    "    \"tqdm\",\n",
    "    \"matplotlib\"\n",
    ")\n",
    "\n",
    "app = App(\"mnist-training\", image=dl_image)\n",
    "\n",
    "# Mount the current directory to save the trained model\n",
    "LOCAL_DIR = os.getcwd()\n",
    "\n",
    "@app.function(\n",
    "    gpu=gpu.T4()\n",
    ")\n",
    "# @mount.from_local_dir(LOCAL_DIR, remote_path=\"/root/outputs\")\n",
    "def train_mnist_model(epochs=5, batch_size=64):\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    from torch.utils.data import DataLoader\n",
    "    from torchvision import datasets, transforms\n",
    "    from tqdm import tqdm\n",
    "    import matplotlib.pyplot as plt\n",
    "    import os\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Define a simple CNN model\n",
    "    class SimpleCNN(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(SimpleCNN, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "            self.relu1 = nn.ReLU()\n",
    "            self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "            self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "            self.relu2 = nn.ReLU()\n",
    "            self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "            self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "            self.relu3 = nn.ReLU()\n",
    "            self.fc2 = nn.Linear(128, 10)\n",
    "            \n",
    "        def forward(self, x):\n",
    "            x = self.pool1(self.relu1(self.conv1(x)))\n",
    "            x = self.pool2(self.relu2(self.conv2(x)))\n",
    "            x = x.view(-1, 64 * 7 * 7)\n",
    "            x = self.relu3(self.fc1(x))\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "    \n",
    "    # Load MNIST dataset\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    \n",
    "    train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Initialize the model\n",
    "    model = SimpleCNN().to(device)\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Training loop\n",
    "    train_losses = []\n",
    "    test_accuracies = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        # Use tqdm for progress bar\n",
    "        with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "            for data, target in tepoch:\n",
    "                tepoch.set_description(f\"Epoch {epoch+1}/{epochs}\")\n",
    "                \n",
    "                data, target = data.to(device), target.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "                tepoch.set_postfix(loss=loss.item())\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += target.size(0)\n",
    "                correct += (predicted == target).sum().item()\n",
    "        \n",
    "        accuracy = 100 * correct / total\n",
    "        test_accuracies.append(accuracy)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Test Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    # Save the model\n",
    "    output_dir = \"/root/outputs\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    model_path = os.path.join(output_dir, \"mnist_model.pth\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "    \n",
    "    # Plot training progress\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses)\n",
    "    plt.title(\"Training Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(test_accuracies)\n",
    "    plt.title(\"Test Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"training_progress.png\"))\n",
    "    \n",
    "    return {\n",
    "        \"final_train_loss\": train_losses[-1],\n",
    "        \"final_test_accuracy\": test_accuracies[-1],\n",
    "        \"model_path\": model_path\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with app.run():\n",
    "        result = train_mnist_model.remote(epochs=5, batch_size=128)\n",
    "        print(\"\\nTraining complete!\")\n",
    "        print(f\"Final training loss: {result['final_train_loss']:.4f}\")\n",
    "        print(f\"Final test accuracy: {result['final_test_accuracy']:.2f}%\")\n",
    "        print(f\"Model saved to: {result['model_path']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a31524",
   "metadata": {},
   "source": [
    "## 6. Fine-tuning a Pretrained Model\n",
    "\n",
    "For more advanced applications, let's fine-tune a pre-trained model on a custom dataset. We'll use a pre-trained vision transformer (ViT) model and fine-tune it on the CIFAR-10 dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91b4cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modal import App, Image, gpu, mount\n",
    "import os\n",
    "\n",
    "# Create an image with huggingface transformers and related dependencies\n",
    "finetune_image = Image.debian_slim().pip_install(\n",
    "    \"torch\", \n",
    "    \"torchvision\", \n",
    "    \"transformers\",\n",
    "    \"datasets\",\n",
    "    \"accelerate\",\n",
    "    \"evaluate\",\n",
    "    \"matplotlib\"\n",
    ")\n",
    "\n",
    "app = App(\"vit-finetune\", image=finetune_image)\n",
    "\n",
    "# Mount the current directory to save the fine-tuned model\n",
    "LOCAL_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "@app.function(\n",
    "    gpu=gpu.T4(),\n",
    "    timeout=3600,  # Allow up to 1 hour for fine-tuning\n",
    "    mounts=[mount.Mount.from_local_dir(LOCAL_DIR, remote_path=\"/root/outputs\")]\n",
    ")\n",
    "def finetune_vit(batch_size=32, num_epochs=3):\n",
    "    import torch\n",
    "    import torchvision\n",
    "    import torchvision.transforms as transforms\n",
    "    from torch.utils.data import DataLoader\n",
    "    from transformers import ViTForImageClassification, ViTImageProcessor\n",
    "    from transformers import TrainingArguments, Trainer\n",
    "    from datasets import load_dataset, load_metric\n",
    "    import numpy as np\n",
    "    import evaluate\n",
    "    import matplotlib.pyplot as plt\n",
    "    import os\n",
    "    \n",
    "    print(\"Setting up fine-tuning process...\")\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load CIFAR-10 dataset using Hugging Face datasets\n",
    "    cifar10 = load_dataset(\"cifar10\")\n",
    "    \n",
    "    # Get the labels\n",
    "    labels = cifar10[\"train\"].features[\"label\"].names\n",
    "    label2id = {label: i for i, label in enumerate(labels)}\n",
    "    id2label = {i: label for i, label in enumerate(labels)}\n",
    "    \n",
    "    # Load pre-trained ViT model and processor\n",
    "    model_name = \"google/vit-base-patch16-224\"\n",
    "    processor = ViTImageProcessor.from_pretrained(model_name)\n",
    "    model = ViTForImageClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=10,\n",
    "        label2id=label2id,\n",
    "        id2label=id2label\n",
    "    )\n",
    "    \n",
    "    # Define image transformations\n",
    "    def transform_images(examples):\n",
    "        images = [img.convert(\"RGB\") for img in examples[\"img\"]]\n",
    "        processed_images = processor(images, return_tensors=\"pt\")\n",
    "        examples[\"pixel_values\"] = processed_images[\"pixel_values\"]\n",
    "        return examples\n",
    "    \n",
    "    # Apply transformations to the dataset\n",
    "    transformed_cifar10 = cifar10.with_transform(transform_images)\n",
    "    \n",
    "    # Define evaluation metrics\n",
    "    accuracy_metric = evaluate.load(\"accuracy\")\n",
    "    \n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        return accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    \n",
    "    # Define training arguments\n",
    "    output_dir = \"/root/outputs/vit-cifar10\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        num_train_epochs=num_epochs,\n",
    "        fp16=True,  # Use mixed precision training\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=5e-5,\n",
    "        remove_unused_columns=False,\n",
    "        push_to_hub=False,\n",
    "        report_to=\"none\",\n",
    "        load_best_model_at_end=True,\n",
    "    )\n",
    "    \n",
    "    # Define Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=transformed_cifar10[\"train\"],\n",
    "        eval_dataset=transformed_cifar10[\"test\"],\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    # Fine-tune the model\n",
    "    print(\"Starting fine-tuning...\")\n",
    "    trainer.train()\n",
    "    \n",
    "    # Evaluate the model\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(f\"Evaluation results: {eval_results}\")\n",
    "    \n",
    "    # Save the fine-tuned model\n",
    "    model_save_path = os.path.join(output_dir, \"final_model\")\n",
    "    trainer.save_model(model_save_path)\n",
    "    processor.save_pretrained(model_save_path)\n",
    "    \n",
    "    # Test the model on a few examples and create visualizations\n",
    "    def predict_and_visualize(dataset, num_samples=5):\n",
    "        samples = dataset.shuffle(seed=42).select(range(num_samples))\n",
    "        images = [sample[\"img\"] for sample in samples]\n",
    "        labels = [sample[\"label\"] for sample in samples]\n",
    "        \n",
    "        # Process images and run prediction\n",
    "        inputs = processor(images, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        preds = outputs.logits.argmax(dim=-1).cpu().numpy()\n",
    "        \n",
    "        # Plot results\n",
    "        fig, axes = plt.subplots(1, num_samples, figsize=(15, 3))\n",
    "        for i, (image, pred, label) in enumerate(zip(images, preds, labels)):\n",
    "            axes[i].imshow(image)\n",
    "            axes[i].set_title(f\"Pred: {id2label[pred]}\\nTrue: {id2label[label]}\")\n",
    "            axes[i].axis(\"off\")\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, \"predictions.png\"))\n",
    "    \n",
    "    print(\"Creating visualizations...\")\n",
    "    predict_and_visualize(transformed_cifar10[\"test\"])\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": eval_results[\"eval_accuracy\"],\n",
    "        \"model_path\": model_save_path,\n",
    "        \"visualizations_path\": os.path.join(output_dir, \"predictions.png\")\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with app.run():\n",
    "        print(\"Starting fine-tuning process...\")\n",
    "        result = finetune_vit.remote(batch_size=16, num_epochs=3)\n",
    "        print(\"\\nFine-tuning complete!\")\n",
    "        print(f\"Final accuracy: {result['accuracy']:.4f}\")\n",
    "        print(f\"Model saved to: {result['model_path']}\")\n",
    "        print(f\"Visualizations saved to: {result['visualizations_path']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52677126",
   "metadata": {},
   "source": [
    "## 7. Distributed Training with Modal\n",
    "\n",
    "Modal makes it easy to run distributed training across multiple GPUs. Let's see how to implement distributed training using PyTorch's DistributedDataParallel (DDP):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aae5bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modal import App, Image, gpu, mount, Stub\n",
    "import os\n",
    "\n",
    "# Create an image with PyTorch and related dependencies\n",
    "distributed_image = Image.debian_slim().pip_install(\n",
    "    \"torch>=1.9.0\", \n",
    "    \"torchvision\", \n",
    "    \"tqdm\"\n",
    ")\n",
    "\n",
    "app = Stub(\"distributed-training\", image=distributed_image)\n",
    "\n",
    "# Mount the current directory to save the trained model\n",
    "LOCAL_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "@app.function(\n",
    "    gpu=gpu.T4(),\n",
    "    mounts=[mount.Mount.from_local_dir(LOCAL_DIR, remote_path=\"/root/outputs\")]\n",
    ")\n",
    "def distributed_trainer(rank, world_size, batch_size=64, epochs=5):\n",
    "    \"\"\"\n",
    "    Function to run on each worker in the distributed training.\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    import torch.distributed as dist\n",
    "    from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "    from torch.utils.data import DataLoader\n",
    "    from torch.utils.data.distributed import DistributedSampler\n",
    "    from torchvision import datasets, transforms\n",
    "    from tqdm import tqdm\n",
    "    import os\n",
    "    \n",
    "    # Initialize the distributed process group\n",
    "    dist.init_process_group(\n",
    "        backend=\"nccl\",  # Use NCCL for GPU training\n",
    "        init_method=\"env://\",\n",
    "        world_size=world_size,\n",
    "        rank=rank\n",
    "    )\n",
    "    \n",
    "    # Set the device for this process\n",
    "    torch.cuda.set_device(0)  # Only one GPU per process in Modal\n",
    "    device = torch.device(\"cuda\")\n",
    "    \n",
    "    # Define a CNN model\n",
    "    class CNN(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(CNN, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "            self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "            self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "            self.fc2 = nn.Linear(128, 10)\n",
    "            self.relu = nn.ReLU()\n",
    "            \n",
    "        def forward(self, x):\n",
    "            x = self.pool(self.relu(self.conv1(x)))\n",
    "            x = self.pool(self.relu(self.conv2(x)))\n",
    "            x = x.view(-1, 64 * 7 * 7)\n",
    "            x = self.relu(self.fc1(x))\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "    \n",
    "    # Create model and move it to the GPU\n",
    "    model = CNN().to(device)\n",
    "    \n",
    "    # Wrap the model with DDP\n",
    "    model = DDP(model, device_ids=[0])\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Define transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    \n",
    "    # Load the MNIST dataset\n",
    "    train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
    "    \n",
    "    # Create distributed sampler\n",
    "    train_sampler = DistributedSampler(\n",
    "        train_dataset,\n",
    "        num_replicas=world_size,\n",
    "        rank=rank\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        sampler=train_sampler\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        dataset=test_dataset,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_sampler.set_epoch(epoch)  # Important to ensure data shuffling\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        if rank == 0:\n",
    "            pbar = tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            if rank == 0 and i % 100 == 99:\n",
    "                pbar.update(100)\n",
    "                pbar.set_postfix(loss=running_loss/100)\n",
    "                running_loss = 0.0\n",
    "                \n",
    "        if rank == 0:\n",
    "            pbar.close()\n",
    "            \n",
    "            # Evaluate the model\n",
    "            model.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in test_loader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "                    \n",
    "            accuracy = 100 * correct / total\n",
    "            print(f\"Epoch {epoch+1}, Accuracy: {accuracy:.2f}%\")\n",
    "            \n",
    "    # Save the model (only on rank 0)\n",
    "    if rank == 0:\n",
    "        output_dir = \"/root/outputs/distributed\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        torch.save(model.module.state_dict(), os.path.join(output_dir, \"distributed_model.pth\"))\n",
    "        print(\"Model saved!\")\n",
    "    \n",
    "    # Clean up the process group\n",
    "    dist.destroy_process_group()\n",
    "    \n",
    "    # Return results from rank 0\n",
    "    if rank == 0:\n",
    "        return {\"accuracy\": accuracy}\n",
    "    return {}\n",
    "\n",
    "@app.function()\n",
    "def run_distributed_training(num_gpus=2, batch_size=64, epochs=5):\n",
    "    \"\"\"\n",
    "    Coordinator function to launch the distributed training.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    # Set up environment variables for distributed training\n",
    "    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "    os.environ[\"MASTER_PORT\"] = \"29500\"\n",
    "    \n",
    "    print(f\"Starting distributed training with {num_gpus} GPUs...\")\n",
    "    \n",
    "    # Run the trainer function on multiple GPUs\n",
    "    futures = []\n",
    "    for rank in range(num_gpus):\n",
    "        future = distributed_trainer.remote(\n",
    "            rank=rank,\n",
    "            world_size=num_gpus,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs\n",
    "        )\n",
    "        futures.append(future)\n",
    "    \n",
    "    # Wait for all processes to complete\n",
    "    results = [future.get() for future in futures]\n",
    "    \n",
    "    # Return the results from rank 0\n",
    "    return results[0]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with app.run():\n",
    "        result = run_distributed_training.remote(num_gpus=2, batch_size=64, epochs=3)\n",
    "        print(\"\\nDistributed training complete!\")\n",
    "        print(f\"Final accuracy: {result.get('accuracy', 'N/A'):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7454bc0c",
   "metadata": {},
   "source": [
    "## 8. Deploying Trained Models as Endpoints\n",
    "\n",
    "Once you've trained your models, you can easily deploy them as API endpoints using Modal. This allows your models to be accessible via HTTP requests, which is perfect for integrating them into other applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72230474",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modal import App, Image, gpu, mount, asgi_app\n",
    "import os\n",
    "\n",
    "# Create an image for model serving\n",
    "serve_image = Image.debian_slim().pip_install(\n",
    "    \"torch\", \n",
    "    \"torchvision\", \n",
    "    \"fastapi\", \n",
    "    \"pillow\", \n",
    "    \"python-multipart\"\n",
    ")\n",
    "\n",
    "app = App(\"model-serving\", image=serve_image)\n",
    "\n",
    "# Mount directory to load saved models\n",
    "LOCAL_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "# Define the model class and loading function\n",
    "@app.cls(\n",
    "    gpu=gpu.T4(),\n",
    "    mounts=[mount.Mount.from_local_dir(LOCAL_DIR, remote_path=\"/root/models\")]\n",
    ")\n",
    "class ModelService:\n",
    "    def __enter__(self):\n",
    "        import torch\n",
    "        import torchvision.transforms as transforms\n",
    "        from PIL import Image\n",
    "        \n",
    "        # Model definition (same as before)\n",
    "        class SimpleCNN(torch.nn.Module):\n",
    "            def __init__(self):\n",
    "                super(SimpleCNN, self).__init__()\n",
    "                self.conv1 = torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "                self.relu1 = torch.nn.ReLU()\n",
    "                self.pool1 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "                self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "                self.relu2 = torch.nn.ReLU()\n",
    "                self.pool2 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "                self.fc1 = torch.nn.Linear(64 * 7 * 7, 128)\n",
    "                self.relu3 = torch.nn.ReLU()\n",
    "                self.fc2 = torch.nn.Linear(128, 10)\n",
    "                \n",
    "            def forward(self, x):\n",
    "                x = self.pool1(self.relu1(self.conv1(x)))\n",
    "                x = self.pool2(self.relu2(self.conv2(x)))\n",
    "                x = x.view(-1, 64 * 7 * 7)\n",
    "                x = self.relu3(self.fc1(x))\n",
    "                x = self.fc2(x)\n",
    "                return x\n",
    "        \n",
    "        # Load the model\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        self.model = SimpleCNN().to(self.device)\n",
    "        \n",
    "        # Try to load from either of the potential locations\n",
    "        model_paths = [\n",
    "            \"/root/models/mnist_model.pth\",\n",
    "            \"/root/outputs/mnist_model.pth\"\n",
    "        ]\n",
    "        \n",
    "        model_loaded = False\n",
    "        for path in model_paths:\n",
    "            try:\n",
    "                self.model.load_state_dict(torch.load(path, map_location=self.device))\n",
    "                print(f\"Model loaded from {path}\")\n",
    "                model_loaded = True\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Could not load from {path}: {e}\")\n",
    "        \n",
    "        if not model_loaded:\n",
    "            print(\"WARNING: Could not load pre-trained model. Using untrained model!\")\n",
    "        \n",
    "        self.model.eval()\n",
    "        \n",
    "        # Define image transformations\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Grayscale(),\n",
    "            transforms.Resize((28, 28)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "        \n",
    "    def predict(self, image_bytes):\n",
    "        import torch\n",
    "        import io\n",
    "        from PIL import Image\n",
    "        \n",
    "        # Load image from bytes\n",
    "        image = Image.open(io.BytesIO(image_bytes))\n",
    "        \n",
    "        # Transform image\n",
    "        image_tensor = self.transform(image).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        # Make prediction\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(image_tensor)\n",
    "            probs = torch.nn.functional.softmax(outputs, dim=1)[0]\n",
    "            predicted_class = torch.argmax(outputs, dim=1).item()\n",
    "            \n",
    "        # Get the top 3 predictions\n",
    "        top_probs, top_classes = torch.topk(probs, 3)\n",
    "        \n",
    "        results = [\n",
    "            {\"class\": int(cls), \"probability\": float(prob)}\n",
    "            for cls, prob in zip(top_classes.cpu().numpy(), top_probs.cpu().numpy())\n",
    "        ]\n",
    "        \n",
    "        return {\n",
    "            \"predicted_class\": predicted_class,\n",
    "            \"top_predictions\": results\n",
    "        }\n",
    "\n",
    "# Create a FastAPI app for the model service\n",
    "from fastapi import FastAPI, File, UploadFile\n",
    "import uvicorn\n",
    "\n",
    "web_app = FastAPI()\n",
    "model_service = ModelService()\n",
    "\n",
    "@web_app.post(\"/predict\")\n",
    "async def predict(file: UploadFile = File(...)):\n",
    "    # Read image file\n",
    "    image_bytes = await file.read()\n",
    "    \n",
    "    # Make prediction using the model service\n",
    "    result = model_service.predict.remote(image_bytes)\n",
    "    return result\n",
    "\n",
    "# Mount the FastAPI app to be served by Modal\n",
    "@app.asgi_app()\n",
    "def fastapi_app():\n",
    "    return web_app\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting model serving app...\")\n",
    "    print(\"Deploy this app with: modal deploy modal_serving.py\")\n",
    "    print(\"Or run locally with: modal serve modal_serving.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0de785a",
   "metadata": {},
   "source": [
    "## 9. Best Practices for Modal GPU Training\n",
    "\n",
    "When using Modal for GPU-accelerated model training, consider the following best practices to optimize performance and cost:\n",
    "\n",
    "### 1. Data Management\n",
    "\n",
    "- **Use data caching**: For large datasets, use Modal volumes to cache preprocessed data\n",
    "- **Optimize data loading**: Use proper batch sizes and data loaders\n",
    "- **Data preprocessing**: Do heavy preprocessing once and save the results\n",
    "\n",
    "### 2. GPU Efficiency\n",
    "\n",
    "- **Choose the right GPU**: Select the GPU type based on your workload needs:\n",
    "  - T4: Good for smaller models, cost-effective\n",
    "  - A10G: Better for medium-sized models\n",
    "  - A100: For large models and faster training\n",
    "  - H100: For the most demanding workloads\n",
    "\n",
    "- **Optimize batch size**: Find the largest batch size that fits in GPU memory\n",
    "\n",
    "- **Use mixed precision training**: FP16 can significantly speed up training\n",
    "\n",
    "### 3. Cost Optimization\n",
    "\n",
    "- **Monitor usage**: Keep track of your GPU usage\n",
    "- **Checkpoint models**: Save checkpoints to resume training\n",
    "- **Use spot instances**: For non-critical workloads, use spot instances for cost savings\n",
    "\n",
    "### 4. Development Workflow\n",
    "\n",
    "- **Test locally first**: Develop and test with small datasets locally\n",
    "- **Use smaller models**: During development, use smaller model variants\n",
    "- **Debug efficiently**: Use Modal's logs and metrics for debugging\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Modal provides a powerful and flexible platform for GPU-accelerated AI model training and deployment. Its key advantages include:\n",
    "\n",
    "- Easy access to powerful GPUs without infrastructure management\n",
    "- Simple scaling from local development to production\n",
    "- Cost-effective pay-per-use pricing model\n",
    "- Streamlined deployment of trained models\n",
    "\n",
    "By following this course, you've learned how to:\n",
    "- Set up Modal for machine learning workflows\n",
    "- Use GPUs for accelerated training\n",
    "- Train deep learning models on Modal\n",
    "- Implement distributed training across multiple GPUs\n",
    "- Deploy trained models as API endpoints\n",
    "\n",
    "To learn more, check out the [Modal documentation](https://modal.com/docs) and explore the [examples repository](https://github.com/modal-labs/modal-examples)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
